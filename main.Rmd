---
title: "main"
output: html_document
date: '2022-06-06'
---

```{r}
library(dplyr)
library(ggplot2)
```

```{r}
data <- read.csv('bike_sharing.csv')
```

```{r}
data <- data %>% 
  mutate(count_cat = cut(
    count, 
    breaks=c(0, 200, 400, 600, 800, 1000),
    labels=c("Sangat Sedikit", "Sedikit", "Sedang", "Banyak", "Sangat Banyak")))
```

```{r}
library(ClusterR)
library(cluster)

set.seed(12)
kmeans.cluster <- kmeans(data$count, centers=5)
kmeans.cluster$cluster
data$count_cat <- kmeans.cluster$cluster
#data$count_cat <- as.factor(data$count_cat)
```

```{r}
ggplot(data, aes(x=as.factor(count_cat), y=count))+
  geom_boxplot()

levels(data$count_cat)[c(1,2,3,4,5)] <- c("Banyak", "Sedikit", "Sangat Sedikit", "Sedang", "Sangat Banyak")
```


```{r}
library(lubridate)
day <- day(dmy_hm(data$datetime))
month <- month(dmy_hm(data$datetime))
year <- year(dmy_hm(data$datetime))
hour <- hour(dmy_hm(data$datetime))

library(tibble)
data <- add_column(data, day=day, .after="datetime")
data <- add_column(data, month=month, .after="day")
data <- add_column(data, year=year, .after="month")
data <- add_column(data, hour=hour, .after="year")

#data$month <- as.factor(data$month)
#data$year <- as.factor(data$year)
```

```{r}
data$season <- as.factor(data$season)
levels(data$season)[c(1,2,3,4)] <- c("winter", "spring", "summer", "fall")

data$weather <- as.factor(data$weather)
levels(data$weather)[c(1, 2, 3, 4)] <- c("good", "normal", "bad", "very bad")

data$holiday <- as.factor(data$holiday)
#levels(data$holiday)[c(0, 1)] <- c("no", "yes")

data$workingday <- as.factor(data$workingday)
#levels(data$workingday)[c(0, 1)] <- c("no", "yes")
```

```{r}
#korelasi kolom kategorikal dengan count_cat
cat_columns = c("month", "season", "holiday", "workingday", "weather")

#FIAINTRP
cat_columns_pvalue = c()
for(col in cat_columns){
  chisq = chisq.test(data$count_cat, data[,col])
  cat_columns_pvalue = append(cat_columns_pvalue, chisq[["p.value"]])
}
df_cat_columns_pvalue = data.frame(cat_columns, cat_columns_pvalue)
df_cat_columns_pvalue
```

```{r}
#korelasi kolom numerik dengan count_cat
num_columns <- c("hour", "temp", "atemp", "humidity", "windspeed")
for(col in num_columns){
  print(summary(aov(data[,col] ~ data[,"count_cat"])))
}
```
```{r}
#plot kolom numerik dengan count_cat
num_columns <- c("hour", "temp", "atemp", "humidity", "windspeed")

for(col in num_columns){
  plot <- ggplot(data, aes_string(x="count_cat", y=col))+
    geom_boxplot()
  
  print(plot)
}
```
```{r}
#plot kolom numerik dengan count_cat
num_columns <- c("hour", "temp", "atemp", "humidity", "windspeed")

for(col in num_columns){
  plot <- ggplot(data, aes_string(x=col, y="count"))+
    geom_point()
  
  print(plot)
}
```

```{r}
cat_columns <- c("month", "season", "holiday", "workingday", "weather")

for(col in cat_columns){
  plot <- ggplot(data, aes_string(x=col, fill="count_cat"))+
    geom_bar(position = "dodge")
  print(plot)
}

```
```{r}
cat_columns <- c("month", "season", "holiday", "workingday", "weather")

for(col in cat_columns){
  plot <- ggplot(data, aes_string(x=col, y="count"))+
    geom_boxplot()
  print(plot)
}

```
```{r}
set.seed(12)

normalize <- function(x){
 (x-min(x))/(max(x)-min(x))
}

data_model <- subset(data, select=-c(datetime, count))

#data_model_num <- data[append(num_columns, c("count_cat"))]
#data_model[num_columns] <- as.data.frame(lapply(data_model[num_columns], normalize))

random <- sort(sample(1:nrow(data_model), 0.8*nrow(data_model),replace=F))
train <- data_model[random,1:12]
test <- data_model[-random,1:12]
train.out <- data_model[random,13]
test.out <- data_model[-random,13]
nrow(train)
nrow(test)
```
```{r}
#ACCURACY
accuracy <- function(x){
 sum(diag(x)/(sum(rowSums(x))))*100
 }
```

```{r}
##Metode 1 - kNN
library(class)
set.seed(12)

accs <- list()

for(i in 1:50){
  knn.pred <- knn(train, test, cl=train.out, k=i)
  #Confusion Matrix
  tab <- table(knn.pred, test.out)
  
  accs <- append(accs, accuracy(tab))
}
plot(1:50, accs, type="o")
```

```{r}
##Metode 2 - LDA
#Modeling dengan LDA
library(MASS)
train.lengkap <- cbind(train, train.out)
colnames(train.lengkap)[13] <- c("count_cat")
test.lengkap <- cbind(test, test.out)
colnames(test.lengkap)[13] <- c("count_cat")
lda <- lda(count_cat~., data = train.lengkap)
lda
plot(lda)
lda.pred <- predict(lda, test.lengkap)
names(lda.pred)
(tab <- table(lda.pred$class, test.out))
accuracy(tab)
```
```{r}
##Support Vector Machine
library(e1071)
#Linear SVM
svmfit = svm(count_cat ~ ., data = train.lengkap, kernel = "linear", cost = 5, 
scale = FALSE, type="C-classification")
print(svmfit)
svml.pred <- predict(svmfit,test)
tab <- table(svml.pred, test.out)
tab
accuracy(tab)
#plot(svmfit, train.lengkap)
```

```{r}
#Non-linear SVM, kernel = radial / polynomial
svmfit1 = svm(count_cat ~ ., data = train.lengkap, scale = FALSE, kernel = 
"radial", cost = 10, type="C-classification")
print(svmfit)
svml.pred <- predict(svmfit1, test)
tab <- table(svml.pred, test.out)
tab
accuracy(tab)
```

```{r}
#Tuning SVM
set.seed(12)
train.lengkap$count_cat <- as.factor(train.lengkap$count_cat)
tuning <- tune(svm, count_cat ~ ., data = train.lengkap,kernel="linear",ranges
=list(cost=c(0.001 , 0.01, 0.1, 1,5,10,100)), type="C-classification")
bestmod =tuning$best.model
print(bestmod)
svrbest.pred <- predict(bestmod,test)
cbind(svrbest.pred,test.out)
mean(svrbest.pred == test.out)
```

```{r}
#Decision Tree
library(rpart)
tm <- rpart(count_cat~., train.lengkap, method = "class")
library(rpart.plot)
rpart.plot(tm, tweak = 1.6)
dc.pred <- predict(tm, test.lengkap, type = "class")
(tab <- table(test.lengkap$count_cat, dc.pred))
accuracy(tab)
```
```{r}
library(randomForest)
randFo1 = randomForest(x = train,y = train.out, ntree = 500, mtry = 6, 
nPerm = 4, nodesize = 5, importance = TRUE)
rf.pred <- predict(randFo1, test.lengkap, type="class")
(tab <- table(test.lengkap$count_cat, rf.pred))
accuracy(tab)
```














